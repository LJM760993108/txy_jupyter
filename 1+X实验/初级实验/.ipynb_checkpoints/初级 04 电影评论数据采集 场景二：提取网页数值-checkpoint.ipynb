{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 场景一 目标站点网页分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "## 任务一 向站点发送请求\n",
    "\n",
    "### 步骤 1\t导入网页请求库requests\n",
    "\n",
    "# requests是Python中的HTTP库，在导入requests库之前，需确认在Python中已安装。\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "\n",
    "### 步骤 2\t配置请求信息\n",
    "\n",
    "\n",
    "# 通过requests.get(url,headers)方法请求网页，其中传入的参数是url和headers。\n",
    "# \turl：目标站点地址信息；\n",
    "# \theaders：浏览器信息，若不添加headers信息，服务器无法识别浏览器信息，则将该请求视为非法请求，无法获取正常的响应结果。最后打印出状态码status_code的返回结果。注意：每个浏览器的请求信息不同，需要根据实际情况传入该参数信息。\n",
    "url = 'https://movie.douban.com/subject/27119724/comments?sort=new_score&status=P'\n",
    "headers = {\n",
    "        'User-Agent':'Mozilla/5.0(Macintosh;Intel Mac OS X 10_14_6)AppleWebKit/537.36(KHTML, like Gecko)Chrome/79.0.3945.130Safari/537.36' }\n",
    "response = requests.get(url,headers = headers)\n",
    "print(response.status_code)\n",
    "\n",
    "\n",
    "## 任务二获取网页内容\n",
    "\n",
    "\n",
    "# 获取网页内容。\n",
    "# \trequests.get()方法请求返回参数text获取网页源代码内容。\n",
    "html = response.text\n",
    "print(type(response.text))\n",
    "\n",
    "\n",
    "## 任务三 网页结构 解析\n",
    "\n",
    "\n",
    "# 请根据网页内容在下表中填写采集数据字段用户名、评论时间、评论内容的标签信息：\n",
    "# 字段\t标签名称\t标签类型\n",
    "# user\t\t\n",
    "# time\t\t\n",
    "# comment\t\t\n",
    "\n",
    "# 【参考答案】\n",
    "# 字段\t标签名称\t标签类型\n",
    "# user\t<a>\tNull\n",
    "# time\t<span>\tcomment-time\n",
    "# comment\t<span>\tshort\n",
    "\n",
    "\n",
    "## 任务四 构造网页获取函数\n",
    "\n",
    "\n",
    "# 构造网页获取函数。\n",
    "# 将以上代码封装为函数，以便于多次调用，自定义函数名称为get_page()，将url作为传入参数。在函数体中，使用if条件语句判断响应状态，若状态码为正常，则返回网页内容；若网页请求失败，则返回None。\n",
    "def get_page(url):\n",
    "    headers = {\n",
    "        'User-Agent':'Mozilla/5.0(Macintosh;Intel Mac OS X 10_14_6)AppleWebKit/537.36(KHTML, like Gecko)Chrome/79.0.3945.130Safari/537.36'\n",
    "        }\n",
    "    try:\n",
    "        response = requests.get(url,headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        return None\n",
    "    except RequestException:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 场景二"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务一 网页解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤 1\t导入BeautifulSoup库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 本次实验采用BeautifulSoup库对网页进行解析，相比于直接提取和正则表达式匹配的方法，\n",
    "# 使用BeautifulSoup更加简洁、高效，导入前需确认已安装BeautifulSoup库。\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 2\t解析网页"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 声明BeautifulSoup对象为soup，并传入html代码和解析方式，BeautifulSoup提供以下4种解析库：\n",
    "# 解析器\t使用方法\t说明\n",
    "# Python标准库\tBeautifulSoup(makeup,”html.parser”)\tPython的内置标准库\n",
    "# lxml HTML解析器\tBeautifulSoup(makeup,”lxml”)\t常用HTML代码解析器\n",
    "# lxml XML解析器\tBeautifulSoup(makeup,”xml”)\t唯一支持XML的解析器\n",
    "# html5lib\tBeautifulSoup(makeup,”html5lib”)\t以浏览器的方式解析文档并生成HTML5格式的文档\n",
    "soup = BeautifulSoup(html, 'lxml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务二 网页数值提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤 1\t提取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \tfind_all()：查找标签，通过class_设置标签类型，class_=\"comment\"和attrs={\"class\": \"comment-info\"}两种写法实现结果相同。\n",
    "# 注意：class在Python中属于关键字， 因此class需要添加下划线。\n",
    "\n",
    "items = soup.find_all(\"div\", class_=\"comment\")\n",
    "for item in items:\n",
    "    info = item.find_all(name='span', attrs={\"class\": \"comment-info\"})\n",
    "    for users in info:\n",
    "        user = users.find_all(name='a', attrs={\"class\": \"\"})[0].string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤 2\t生成格式化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \tyield{}：yield方法为生成器，迭代地将数据返回结果写入字典中；\n",
    "# \tstrip()：strip方法用于去掉字符串中多余的空格。\n",
    "def parse_page(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    items = soup.find_all(\"div\", class_=\"comment\")\n",
    "    for item in items:\n",
    "        info = item.find_all(name='span', attrs={\"class\": \"comment-info\"})\n",
    "        for users in info:\n",
    "            user = users.find_all(name='a', attrs={\"class\": \"\"})[0].string\n",
    "        yield{\n",
    "            \"user\":user,\n",
    "            \"time\":item.find_all(name='span', attrs={\"class\":\"comment-time\"})[0].string.strip(),\n",
    "            \"comment\":item.find_all(name='span', attrs={\"class\":\"short\"})[0].string\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object parse_page at 0x7f09c22b67d0>\n"
     ]
    }
   ],
   "source": [
    "for i in parse_page(html):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
